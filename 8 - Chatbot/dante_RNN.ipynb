{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dante_RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/nlp00/blob/master/8%20-%20Chatbot/dante_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4MjpjKzAue78",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generare testo con le Reti Ricorrenti (LSTM)\n",
        "In questo notebook vederemo come è possibile utilizzare le reti neurali ricorrenti LSTM non solamente per classificare del testo ma anche per generarlo ! Quello che andremo a fare è cercare di generare del nuovo testo con lo stesso stile che ha utilizzato Dante Alighieri per scrivere la Divina Commedia.<br><br>\n",
        "Cominciamo scaricando una copia gratuita in TXT della Divina Commedia, puoi otterla da [questo sito internet](https://www.liberliber.it/online/autori/autori-a/dante-alighieri/la-divina-commedia-edizione-petrocchi/), se utilizzi Google Colaboratory o hai wget installato esegui pure il comando qui sotto per scaricare il file."
      ]
    },
    {
      "metadata": {
        "id": "q3cb6BFDHJ44",
        "colab_type": "code",
        "outputId": "268cff75-b9d5-4151-e48d-8ac2a1c1f9c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.liberliber.it/mediateca/libri/a/alighieri/la_divina_commedia/txt/la_divin.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-24 12:47:40--  https://www.liberliber.it/mediateca/libri/a/alighieri/la_divina_commedia/txt/la_divin.zip\n",
            "Resolving www.liberliber.it (www.liberliber.it)... 93.186.244.67\n",
            "Connecting to www.liberliber.it (www.liberliber.it)|93.186.244.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 232691 (227K) [application/zip]\n",
            "Saving to: ‘la_divin.zip’\n",
            "\n",
            "la_divin.zip        100%[===================>] 227.24K   663KB/s    in 0.3s    \n",
            "\n",
            "2019-04-24 12:47:41 (663 KB/s) - ‘la_divin.zip’ saved [232691/232691]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-bnyH7aNxWV_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ed estrai lo zip."
      ]
    },
    {
      "metadata": {
        "id": "_kJMMCZmIgvK",
        "colab_type": "code",
        "outputId": "62912171-4b86-4ac6-9ac4-14c76eae3feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip la_divin.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  la_divin.zip\n",
            "  inflating: la_divin.txt            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B6knMxL-xcTO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Processiamo i dati\n",
        "Apriamo il file appena scaricato, leggiamone il contenuto e stampiamo i primi 100 caratteri."
      ]
    },
    {
      "metadata": {
        "id": "r6Jb2lDdJ4rJ",
        "colab_type": "code",
        "outputId": "e5e53c67-218a-4d9f-b808-3ae401f7265a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "cell_type": "code",
      "source": [
        "with open(\"la_divin.txt\", encoding=\"latin-1\") as divine_file:\n",
        "  divine_txt = divine_file.read()\n",
        "  \n",
        "print(divine_txt[:100])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dante Alighieri\n",
            "La Divina Commedia\n",
            "\n",
            "Questo e-book è stato realizzato anche grazie al sostegno di:\n",
            "E-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dn_cBlzg9PDm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Come vedi l'ebook contiene del testo che non ci interessa, usiamo il metodo *.find(text)* per trovare dove inizia e finisce la divina commedia ed eseguiamo lo slicing per tenere soltanto il testo scritto da Dante."
      ]
    },
    {
      "metadata": {
        "id": "l8fKWhRlKLPR",
        "colab_type": "code",
        "outputId": "c553c5dd-2fec-49f5-bad8-0b4beca4e0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "start = divine_txt.find(\"Nel mezzo del cammin di nostra vita\")\n",
        "end = divine_txt.find(\"l'amor che move il sole e l'altre stelle.\")\n",
        "\n",
        "divine_txt = divine_txt[start:end]\n",
        "\n",
        "print(divine_txt[:100])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura,\n",
            "ché la diritta via era smarrit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qLp-hGs090pc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ogni canto contiene una piccola introduzione, ad esempio il primo:\n",
        "<br><br>\n",
        "LA DIVINA COMMEDIA\n",
        "<br>\n",
        "di Dante Alighieri\n",
        "<br>\n",
        "<br>\n",
        "INFERNO\n",
        "<br>\n",
        "<br>\n",
        "CANTO I\n",
        "<br>\n",
        "[Incomincia la Comedia di Dante Alleghieri di Fiorenza, ne la quale tratta de le pene e punimenti de' vizi e de' meriti e premi de le virt˘. Comincia il canto primo de la prima parte la quale si chiama Inferno, nel qual l'auttore fa proemio a tutta l'opera.]<br>\n",
        "<br><br>\n",
        "Il pattern è uguale per ogni canto, quindi possiamo rimuoverlo con un po' di codice:\n",
        " - Usiamo un'espressione regolare per rimuovere tutte le parole che cominciano con almeno due lettere maiscuole.\n",
        " - Usiamo un'altra espressione regolare per rimuovere tutte le frasi contenute tra parentesi quadre.\n",
        " - Rimuoviamo ogni occorrenza della frase 'di Dante Alighieri' dal testo.\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "R_WfHALrSGQG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "divine_txt = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", divine_txt)\n",
        "divine_txt = re.sub(\"[A-Z][A-Z]+\",\"\",divine_txt)\n",
        "\n",
        "divine_txt = divine_txt.replace(\"di Dante Alighieri\",\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0e7aDtoP-LF6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usiamo la solita espressione regolare per rimuovere la punteggiatura, poi rimuoviamo anche i caratteri di 'a capo' e convertiamo tutto il testo in minuscolo."
      ]
    },
    {
      "metadata": {
        "id": "yUPTo6T8_jBh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "divine_txt = re.sub(r'[^\\w\\s]','',divine_txt)\n",
        "divine_txt = divine_txt.replace(\"\\n\",\" \")\n",
        "divine_txt = divine_txt.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0MOxj8ig_xCg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adesso siamo pronti per tokenizzare il testo, usiamo spacy per farlo. Se non lo abbiamo già fatto installiamo il modulo per la lingua italiana."
      ]
    },
    {
      "metadata": {
        "id": "1p0leKS7ed-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "b3f117b3-b5a2-4972-95c0-1e480050a9f0"
      },
      "cell_type": "code",
      "source": [
        "!python -m spacy download it_core_news_sm"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting it_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-2.0.0/it_core_news_sm-2.0.0.tar.gz#egg=it_core_news_sm==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-2.0.0/it_core_news_sm-2.0.0.tar.gz (36.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 36.5MB 32.0MB/s \n",
            "\u001b[?25hInstalling collected packages: it-core-news-sm\n",
            "  Running setup.py install for it-core-news-sm ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed it-core-news-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/it_core_news_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/it_core_news_sm\n",
            "\n",
            "    You can now load the model via spacy.load('it_core_news_sm')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IDWfVjyzAECM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Carichiamolo, definiamo una funzione che estrae i token da tutto il testo ed utilizziamola."
      ]
    },
    {
      "metadata": {
        "id": "Uw_ynE1men3a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "9d47e04e-632e-4972-8d6d-6384a876a757"
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"it_core_news_sm\")\n",
        "\n",
        "def preprocess(text):\n",
        "\n",
        "  tokens = nlp(text)\n",
        "  tokens_filtered = [token.text for token in tokens]\n",
        "  return tokens_filtered\n",
        "\n",
        "tokens = preprocess(divine_txt)\n",
        "tokens[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nel',\n",
              " 'mezzo',\n",
              " 'del',\n",
              " 'cammin',\n",
              " 'di',\n",
              " 'nostra',\n",
              " 'vita',\n",
              " 'mi',\n",
              " 'ritrovai',\n",
              " 'per']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "CAyfyrqeCacv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Suddividiamo il testo in sequenze con una lunghezza massima di 10 parole, lo scopo delle nostra rete sarà quello di predire l'ultima parola della sequenza utilizzando quelle precedenti, per quale motivo utilizziamo questo approccio ? Lo vedrremo più avanti, per adesso fidati."
      ]
    },
    {
      "metadata": {
        "id": "6oXESRj8dUx3",
        "colab_type": "code",
        "outputId": "cb52934c-2427-4af9-e48d-0b299fbbb696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "maxlen = 10\n",
        "\n",
        "divine_sents = []\n",
        "\n",
        "for i in range(maxlen, len(tokens)):\n",
        "  divine_sents.append(tokens[i-maxlen:i])\n",
        "  \n",
        "print(divine_sents[0])\n",
        "print(divine_sents[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['nel', 'mezzo', 'del', 'cammin', 'di', 'nostra', 'vita', 'mi', 'ritrovai', 'per']\n",
            "['mezzo', 'del', 'cammin', 'di', 'nostra', 'vita', 'mi', 'ritrovai', 'per', 'una']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AoHbrCD6APDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adesso dobbiamo codificare le parole in numeri, possiamo farlo creandoci un dizionario di tutte le parole contenute nel testo e poi sostituire i token di ogni frase con la corrispondente posizione della parola nel dizionario. Per farlo possiamo usare direttamente la classe *Tokenizer* di keras che fa tutto per noi."
      ]
    },
    {
      "metadata": {
        "id": "ZLBDHWQZWpm8",
        "colab_type": "code",
        "outputId": "52a3cbfe-dab8-4c0c-f5b9-ddfd020f49e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(divine_sents)\n",
        "divine_sents = tokenizer.texts_to_sequences(divine_sents)\n",
        "\n",
        "divine_sents[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[38, 224, 24, 603, 4, 186, 153, 15, 13574, 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "VsX1IDh4DInb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creiamo i set con features e target, come già detto i features saranno i tokens di una seguenza eccetto l'ultimo, il target sarà invece proprio quest'ultimo token."
      ]
    },
    {
      "metadata": {
        "id": "24kyU6HsiTf5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "divine_sents = np.array(divine_sents)\n",
        "\n",
        "X = divine_sents[:,:-1]\n",
        "y = divine_sents[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ce3zIOi0DRa7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Il nostro si tratta di un problema di classificazione multiclasse, le cui possibili classi sono tutte le parole contenute nel dizionario, vediamo quante sono esattamente."
      ]
    },
    {
      "metadata": {
        "id": "jrMSeOUxDbi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51de128b-7c67-4a22-9cd9-9091d1c050f1"
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_counts)\n",
        "vocab_size"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13574"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "C42AzDVdDhl-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Abbiamo in totale 13575 parole, usiamo la funzione *to_categorical(y)* di keras per eseguire il one hot encoding delle variabili target."
      ]
    },
    {
      "metadata": {
        "id": "UteQnvyqcXbl",
        "colab_type": "code",
        "outputId": "21821357-6b9b-42d4-da06-228440795a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y, num_classes=vocab_size+1)\n",
        "y.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97393, 13575)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "SVLejwLXDtto",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creazione della Rete Ricorrente\n",
        "Creiamo la nostra architettura di rete neurale ricorrente:\n",
        " - Utilizziamo il *Word Embedding* per creare una rappresentazione vettoriale delle parole, addestrandolo sul nostro corpus di testo.\n",
        " - Aggiungiamo due strati ricorrenti con 50 nodi ciascuno, il primo dei quali dovrà ritornare una sequenza che servirà come input per il secondo.\n",
        " - Aggiungiamo un terzo strato denso con sempre 50 nodi.\n",
        " - Infine inseriamo uno strato di output con un numero di nodi ovviamente pari al numero di parole nel dizionario."
      ]
    },
    {
      "metadata": {
        "id": "zunahaBbkbdc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import Model, Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size+1, maxlen-1, input_length=maxlen-1))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(50, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size+1, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XbIju0mJE6tI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compiliamo il modello, trattandosi di un problema di classificazione multiclasse useremo la *categorical crossentropy* come funzione di costo, come algoritmo di ottimizzazione usiamo *rmsprop* che dovrebbe portare a migliori risultati se utilizziamo le reti ricorrenti."
      ]
    },
    {
      "metadata": {
        "id": "7Y29LJ9Dk596",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIwa1NW2FNTU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Come abbiamo detto, quello che vogliamo fare è creare una rete neurale in grado di generare testo dantesco, quindi perché stiamo eseguendo una classificazione ? L'utilizzo che faremo della rete è il seguente:\n",
        "1. Forniremo alla rete del testo 'seed' di una lunghezza prestabilita, cioè del testo di base che poi essa userà per generare quello seguente, possiamo definire noi tale testo oppure estrarlo a caso dal corpus.\n",
        "2. La rete predirà la parola che secondo essa dovrebbe seguire il testo 'seed'.\n",
        "3. Aggiungiamo la parola predetta al testo.\n",
        "4. Rimuoviamo la prima parola del testo.\n",
        "5. Ripetiamo i punti da 2 a 4 fino a quando il testo predetto non avrà la lunghezza che vogliamo.\n",
        "\n",
        "Definiamo una funzione che fa esattamente questo."
      ]
    },
    {
      "metadata": {
        "id": "OyIROaQBywkt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate(seed=None, rand_seed_len=10, generate_len=25):\n",
        "  \n",
        "  output = \"\"\n",
        "  \n",
        "  if(seed==None):\n",
        "    start_index = randint(0, len(divine_txt))\n",
        "    text = divine_txt[start_index:start_index+rand_seed_len]\n",
        "  else:\n",
        "    text=seed\n",
        "    \n",
        "  for i in range(generate_len):\n",
        "    tokens = np.array(tokenizer.texts_to_sequences([text]))\n",
        "    tokens = pad_sequences(tokens, maxlen=maxlen-1, truncating=\"pre\")\n",
        "      \n",
        "    pred_word = model.predict_classes([tokens])[0]\n",
        "    pred_word = tokenizer.index_word[pred_word]\n",
        "      \n",
        "    text+=\" \"+pred_word\n",
        "    output+=pred_word+\" \"\n",
        "    \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dmRL1QNLGdIA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Utilizzando keras è possibile definire una funzione che viene eseguita al termine di ogni epoca dell'addestramento, definiamo una funzione che chiama la funzione per generare il testo, in modo tale da vedere come la qualità del testo varia durante l'addestramento."
      ]
    },
    {
      "metadata": {
        "id": "EZ_xC_G4GdoA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_on_epoch(epoch, _):\n",
        "  output = generate()\n",
        "  print('Dante dice: \"'+output+'\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-3bwHvkGwpU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adesso siamo pronti per l'addestramento, per chiamare la funzione appena definita ad ogni epoca dobbiamo utilizzare i callback.\n",
        "Creiamo un Lambda Callback passando all'interno del parametro on_epoch_end il nome della funzione.\n",
        "Aggiungiamo il callback all'interno del parametro *callbacks* del metodo *.fit()*.\n",
        "<br>\n",
        "Keras ci mette a disposizone diversi callbacks da utilizzare durante l'addestramento, un'altro molto utile è quello per eseguire **l'early stopping**, cioè quella tecnica che ci permette di terminare l'addestramento in anticipo se la qualità del modello non sta migliorando. Utilizziamo l'early stopping con la classe *EarlyStopping* utilizzando i parametri *min_delta* e *patience* per interrompere l'addestramento se il valore della log loss non migliora di almeno 0.001 dopo 5 epoche.\n",
        "<br><br>\n",
        "**NOTA BENE**\n",
        "<br>\n",
        "Se non hai una GPU che supporta la tecnologia CUDA e non vuoi usare Google Colaboratory, ti consiglio di importare il modello pre-addestrato eseguendo il codice che trovi nella cella poco più sotto, altrimenti l'addestramento potrebbe richiedere anche giorni e mettere sotto forte stress il tuo pc."
      ]
    },
    {
      "metadata": {
        "id": "TEjQFmPklCQ4",
        "colab_type": "code",
        "outputId": "96c2fc09-b935-4afc-bdce-72c8b303f50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7974
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, LambdaCallback\n",
        "\n",
        "epoch_end_callback = LambdaCallback(on_epoch_end=generate_on_epoch)\n",
        "earlyStopping = EarlyStopping(min_delta=0.001, patience=5)\n",
        "model.fit(X, y, batch_size=128, epochs=500, callbacks=[earlyStopping, epoch_end_callback])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "97393/97393 [==============================] - 36s 368us/step - loss: 7.4445 - acc: 0.0406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dante dice: \"che che che che che che che che che che che che che che che che che che che che che che che che che \"\n",
            "Epoch 2/500\n",
            "97393/97393 [==============================] - 33s 338us/step - loss: 7.0821 - acc: 0.0404\n",
            "Dante dice: \"e e e e e e e e e e e e e e e e e e e e e e e e e \"\n",
            "Epoch 3/500\n",
            "97393/97393 [==============================] - 32s 325us/step - loss: 6.9634 - acc: 0.0462\n",
            "Dante dice: \"che che che che che che che che che che che che che che che che che che che che che che che che che \"\n",
            "Epoch 4/500\n",
            "97393/97393 [==============================] - 33s 341us/step - loss: 6.8422 - acc: 0.0535\n",
            "Dante dice: \"e che che che che che che che che che che che che che che che che che che che che che che che che \"\n",
            "Epoch 5/500\n",
            "97393/97393 [==============================] - 33s 342us/step - loss: 6.7532 - acc: 0.0568\n",
            "Dante dice: \"e l occhi e che la occhi e che che che che che che che che che che che che che che che che che \"\n",
            "Epoch 6/500\n",
            "97393/97393 [==============================] - 33s 335us/step - loss: 6.6568 - acc: 0.0600\n",
            "Dante dice: \"occhi che che la occhi e che che la occhi e che che la occhi e che che la occhi e che che la occhi \"\n",
            "Epoch 7/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 6.5539 - acc: 0.0617\n",
            "Dante dice: \"che la occhi che l occhi e che la occhi e che la occhi e che la occhi e che la occhi e che la \"\n",
            "Epoch 8/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 6.4678 - acc: 0.0640\n",
            "Dante dice: \"che la occhi e non si occhi e che l occhi e che l occhi e che l occhi e che l occhi e che \"\n",
            "Epoch 9/500\n",
            "97393/97393 [==============================] - 33s 334us/step - loss: 6.3976 - acc: 0.0654\n",
            "Dante dice: \"che l occhi e non si occhi e non si occhi e non si occhi e non si occhi e non si occhi e non \"\n",
            "Epoch 10/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 6.3342 - acc: 0.0672\n",
            "Dante dice: \"che l occhi e si occhi e non si occhi e non si occhi e non si occhi e non si occhi e non si \"\n",
            "Epoch 11/500\n",
            "97393/97393 [==============================] - 33s 335us/step - loss: 6.2725 - acc: 0.0691\n",
            "Dante dice: \"che non si occhi e non si occhi e non si occhi e non si occhi e non si occhi e non si occhi e \"\n",
            "Epoch 12/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 6.2085 - acc: 0.0721\n",
            "Dante dice: \"che si occhi e che si occhi e che si occhi e che si occhi e che si occhi e che si occhi e che \"\n",
            "Epoch 13/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 6.1420 - acc: 0.0747\n",
            "Dante dice: \"e si occhi e si occhi e che si occhi e si occhi e che si occhi e si occhi e che si occhi e \"\n",
            "Epoch 14/500\n",
            "97393/97393 [==============================] - 34s 347us/step - loss: 6.0735 - acc: 0.0775\n",
            "Dante dice: \"occhi e si occhi e che si occhi e si occhi e che si occhi e si occhi e che si occhi e si occhi \"\n",
            "Epoch 15/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 6.0056 - acc: 0.0801\n",
            "Dante dice: \"e non si occhi e si occhi e l occhi miei e si occhi e si occhi e si occhi e si occhi e si \"\n",
            "Epoch 16/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 5.9404 - acc: 0.0822\n",
            "Dante dice: \"me e si occhi e e si occhi e e si occhi e e si occhi e e si occhi e e si occhi e \"\n",
            "Epoch 17/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 5.8754 - acc: 0.0837\n",
            "Dante dice: \"l occhi e l occhi e e si occhi e e si occhi e e si occhi e e si occhi e e si occhi \"\n",
            "Epoch 18/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 5.8106 - acc: 0.0865\n",
            "Dante dice: \"e l suo vita e e e e e si occhi e e si occhi e e si occhi e e si occhi e e \"\n",
            "Epoch 19/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 5.7445 - acc: 0.0880\n",
            "Dante dice: \"la occhi e si occhi e e si occhi e e si occhi e e si occhi e e si occhi e e si occhi \"\n",
            "Epoch 20/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 5.6792 - acc: 0.0907\n",
            "Dante dice: \"occhi sue e si occhi e e si occhi e e si occhi e e si occhi e e si occhi e e si occhi \"\n",
            "Epoch 21/500\n",
            "97393/97393 [==============================] - 33s 339us/step - loss: 5.6135 - acc: 0.0930\n",
            "Dante dice: \"che si occhi e e si occhi e e si occhi e e si occhi e e si occhi e e si occhi e e \"\n",
            "Epoch 22/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 5.5502 - acc: 0.0950\n",
            "Dante dice: \"che e anni e l occhi miei e per lor si sue note e si occhi de la occhi miei e si occhi de la \"\n",
            "Epoch 23/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 5.4846 - acc: 0.0969\n",
            "Dante dice: \"sue e e si occhi de la mente miei e si occhi de la mente miei e si occhi de la mente miei e si \"\n",
            "Epoch 24/500\n",
            "97393/97393 [==============================] - 33s 337us/step - loss: 5.4212 - acc: 0.0988\n",
            "Dante dice: \"e si disse e l occhi miei e si occhi e e si sue note e l occhi miei e si occhi e e si \"\n",
            "Epoch 25/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 5.3614 - acc: 0.1004\n",
            "Dante dice: \"che l suo vita onde torcesse e mi sue deva e quel e si disse e non anni e l occhi miei e si disse \"\n",
            "Epoch 26/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 5.2995 - acc: 0.1026\n",
            "Dante dice: \"discendo e si disse che l occhi sue e e si occhi de le sue sue note e l occhi miei e per lor vita \"\n",
            "Epoch 27/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 5.2464 - acc: 0.1047\n",
            "Dante dice: \"si sue ministri e quindi si occhi antiche e geli volte che vi sue orme si occhi antiche e geli volte e si disse tetro \"\n",
            "Epoch 28/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 5.1895 - acc: 0.1068\n",
            "Dante dice: \"che tignemmo a me che si sue ancelle onde non ti sue parole e per lor parte e si fece e si fece e per \"\n",
            "Epoch 29/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 5.1334 - acc: 0.1092\n",
            "Dante dice: \"me che moda e poi che sabellio e poco e per altro che e sì menai le sue ali si disse che l occhi mio \"\n",
            "Epoch 30/500\n",
            "97393/97393 [==============================] - 32s 328us/step - loss: 5.0799 - acc: 0.1122\n",
            "Dante dice: \"a me si disse e non simpola e calcabrina e che faccendosi e fedir deï quieu erbette e geli volte che rifëo tulïo e atra \"\n",
            "Epoch 31/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 5.0298 - acc: 0.1164\n",
            "Dante dice: \"me si disse adima a la mente e l suo maestro onde l occhi miei e per lor parti si fé parole pruovi che si \"\n",
            "Epoch 32/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 4.9838 - acc: 0.1198\n",
            "Dante dice: \"che tignemmo e che tu trascorri che non si sue e e rui binato e agra è zanche e strambe è poco e non volte \"\n",
            "Epoch 33/500\n",
            "97393/97393 [==============================] - 32s 329us/step - loss: 4.9402 - acc: 0.1219\n",
            "Dante dice: \"e si disse e l occhi miei e per lor saettando e condur ogne denti chavean i duca mio e e di mare cocca ed \"\n",
            "Epoch 34/500\n",
            "97393/97393 [==============================] - 33s 339us/step - loss: 4.8966 - acc: 0.1256\n",
            "Dante dice: \"teran possenti ma l occhi mio che non ritto coverto o quel continüando e dïone apposto giù e l mio maestro e l maestro mio \"\n",
            "Epoch 35/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 4.8540 - acc: 0.1282\n",
            "Dante dice: \"mia parole sordel non e di qua mio e e si fece e per langelo e rallarga si fece e l duca mio e timeo \"\n",
            "Epoch 36/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 4.8129 - acc: 0.1323\n",
            "Dante dice: \"minonda e là sù che l mondo sedusse le sue ancelle darno e come si fece isnello che quel che di mia vita onde torcesse \"\n",
            "Epoch 37/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 4.7730 - acc: 0.1357\n",
            "Dante dice: \"quel creta ma l mondo del mio duca mio so che si sue parole e piana e                 \"\n",
            "Epoch 38/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 4.7362 - acc: 0.1382\n",
            "Dante dice: \"me avvenia che là giù e raggeran in mio limagini e quel che l maestro che e digrignan l mondo suo che e restai che \"\n",
            "Epoch 39/500\n",
            "97393/97393 [==============================] - 33s 334us/step - loss: 4.7001 - acc: 0.1424\n",
            "Dante dice: \"destino o poco dispettosa e morda che là mio si sue superillustrans claritate sue parole divenuta lune                                                         \"\n",
            "Epoch 40/500\n",
            "97393/97393 [==============================] - 32s 329us/step - loss: 4.6608 - acc: 0.1446\n",
            "Dante dice: \"si vedrà e si fece ma la mondo poverella o venerunt trafuggò la mondo suo che di parte onde l mondo occupa e l mondo \"\n",
            "Epoch 41/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 4.6318 - acc: 0.1479\n",
            "Dante dice: \"parevi giù e veggion le labbra mozzi explicit imo dascian la duca mio mi disse adima sì che l suo subietto sue dartù ricominciò mero \"\n",
            "Epoch 42/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 4.6006 - acc: 0.1506\n",
            "Dante dice: \"ti parrà lanimo onde anche che annotta ragiono e si sue tapini che si fa taccia coram patre onde e ntendendo a me langoscia che \"\n",
            "Epoch 43/500\n",
            "97393/97393 [==============================] - 33s 334us/step - loss: 4.5670 - acc: 0.1544\n",
            "Dante dice: \"destino o arno alberga e per istrane che l sciagurato miei e lasciommi viemmi le occhi sue grommate le ciglia e di quïetarmi quante am \"\n",
            "Epoch 44/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 4.5382 - acc: 0.1580\n",
            "Dante dice: \"è là giù e parton ogne calla uscicci si fé e la suo famiglia mi disse come non volte e si sue mäi e grida \"\n",
            "Epoch 45/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 4.5087 - acc: 0.1599\n",
            "Dante dice: \"martiro gridavano e passarmen mi vedrà isnello che satolli agnello sferza che mi ricerna e io che l monimenti anno medicina e attenti a me \"\n",
            "Epoch 46/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 4.4830 - acc: 0.1623\n",
            "Dante dice: \"e proverai in te che potëa dannose ed el piegò santafior se non è che non si disse e l sabbion                             \"\n",
            "Epoch 47/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 4.4499 - acc: 0.1654\n",
            "Dante dice: \"che vinta e tarde e l duca mio so io vidi che tu si fece ma la mazza occhi ito e l occhi miei e \"\n",
            "Epoch 48/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 4.4248 - acc: 0.1695\n",
            "Dante dice: \"son tu costì intende e si facci brusciato e bruggia potesser ricominciò l mia voglia che l suo voglia prenderò l ridì mio vidi di \"\n",
            "Epoch 49/500\n",
            "97393/97393 [==============================] - 33s 339us/step - loss: 4.3968 - acc: 0.1715\n",
            "Dante dice: \"al duca mio tegno giù inclita lor salvamento io levai a me si ricorda e ricevesse e caliga è lasciavam fecesi vos prec che le \"\n",
            "Epoch 50/500\n",
            "97393/97393 [==============================] - 31s 321us/step - loss: 4.3709 - acc: 0.1747\n",
            "Dante dice: \"dove l rostro un freno ma qua introcque                                                                                                                        \"\n",
            "Epoch 51/500\n",
            "97393/97393 [==============================] - 32s 332us/step - loss: 4.3495 - acc: 0.1781\n",
            "Dante dice: \"come vidi adora a là e poi che non ascondo a me che si fa sovvenir e ntanto la su la trama a dio e \"\n",
            "Epoch 52/500\n",
            "97393/97393 [==============================] - 31s 321us/step - loss: 4.3229 - acc: 0.1799\n",
            "Dante dice: \"che non si dimostra che l altri che n su la suo marra che non nòi ciò che l suo foresta aguzza il mio che \"\n",
            "Epoch 53/500\n",
            "97393/97393 [==============================] - 32s 334us/step - loss: 4.2991 - acc: 0.1828\n",
            "Dante dice: \"medesimo nascimenti si rifonde mio e iv se si fa e si fosse tue si disse se tu di cura prega io non si fa \"\n",
            "Epoch 54/500\n",
            "97393/97393 [==============================] - 32s 332us/step - loss: 4.2779 - acc: 0.1854\n",
            "Dante dice: \"scoglio del mondo lancella si disse come confina ma la classe barbarossa di quel cominciansi la mia monte si giuro loffense parte del suo basterna \"\n",
            "Epoch 55/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 4.2580 - acc: 0.1884\n",
            "Dante dice: \"fascio rara e diserrare che l suo risposta brusca al dipartire del su lomero mondo e attende vice a sangue dora e cappelletti monaldi in \"\n",
            "Epoch 56/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 4.2350 - acc: 0.1898\n",
            "Dante dice: \"piagni indarno dove nacqu io disse e non a la roba occhi giunse e parleremo a me si ricorda che mascolte che cesare e non \"\n",
            "Epoch 57/500\n",
            "97393/97393 [==============================] - 31s 321us/step - loss: 4.2131 - acc: 0.1927\n",
            "Dante dice: \"a nino e di portarne dove e damendue giù non non arda in mio aguta potrete ostante che la rivedrai mi fa riprender fïate seguiterieno \"\n",
            "Epoch 58/500\n",
            "97393/97393 [==============================] - 31s 321us/step - loss: 4.1961 - acc: 0.1942\n",
            "Dante dice: \"fuggisti le sue parole etade o massettai e videmi e conobbemi e private ma mi volse ma disse serse rifiuta tu non si fa guance \"\n",
            "Epoch 59/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 4.1740 - acc: 0.1967\n",
            "Dante dice: \"imago ad artigliar con le sue braccia si convertïan le sue schiere strada seguitò le labbra miei e l suo risposta si poteo parole e \"\n",
            "Epoch 60/500\n",
            "97393/97393 [==============================] - 31s 321us/step - loss: 4.1533 - acc: 0.1994\n",
            "Dante dice: \"fummo laltrui sodalizio giù che l duca mio mabbandono occhi e girerommi che la sponda e si fece e promettendo di vederlo vere isnelle si \"\n",
            "Epoch 61/500\n",
            "97393/97393 [==============================] - 32s 332us/step - loss: 4.1359 - acc: 0.2024\n",
            "Dante dice: \"che ti parrà perfetti le occhi miei che l mondo del regno svegliati non volte ma non si fa corna io dismento digiunar informativa ivi \"\n",
            "Epoch 62/500\n",
            "97393/97393 [==============================] - 32s 331us/step - loss: 4.1134 - acc: 0.2041\n",
            "Dante dice: \"per urlare schembo che non satisfara ma non si stingue e a me si nvita ma l mondo antichi che l sabbion                      \"\n",
            "Epoch 63/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 4.0968 - acc: 0.2062\n",
            "Dante dice: \"passuri e guittone e quel frustato enigma sovresso l occhi sariesi sermo ad essa gioia il suo raggio mese a quel punto che l tinto \"\n",
            "Epoch 64/500\n",
            "97393/97393 [==============================] - 32s 332us/step - loss: 4.0785 - acc: 0.2086\n",
            "Dante dice: \"per pasciuti per quel che si facci e labbagliato cammine tristano e questo che e a sé ornate lodiam io fosti e si fa parole \"\n",
            "Epoch 65/500\n",
            "97393/97393 [==============================] - 31s 320us/step - loss: 4.0533 - acc: 0.2124\n",
            "Dante dice: \"ïo incontro e scopersi la sua giustizia che si converrebbe e poi che vivete ogne chieder si fa parole preciso e si fece e rimiri \"\n",
            "Epoch 66/500\n",
            "97393/97393 [==============================] - 32s 331us/step - loss: 4.0381 - acc: 0.2136\n",
            "Dante dice: \"là giù cascherò io levai e vidi non chiede il duca e dal suo regno e non è nomati e platone che non è che \"\n",
            "Epoch 67/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 4.0203 - acc: 0.2167\n",
            "Dante dice: \"conversi torce e io a me si fa sovvenir che vinta e foss io che l suo solco avvolti a la sua spuola umane iarba \"\n",
            "Epoch 68/500\n",
            "97393/97393 [==============================] - 32s 328us/step - loss: 4.0070 - acc: 0.2170\n",
            "Dante dice: \"nferno soffersi si girava e l uomini materno piovean per qua girando udiremo e trane la sua frui ditemi che veggion lombra tenuto ma dimmi \"\n",
            "Epoch 69/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.9894 - acc: 0.2185\n",
            "Dante dice: \"chaddorna lapparenza e l mio che la classe maestro che cheggioti di poco e la mia vista rude e più conoscitor a la sua borsa \"\n",
            "Epoch 70/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.9742 - acc: 0.2213\n",
            "Dante dice: \"e l spaürato si stenta in dimandarla varcai legata e l duca gottifredi el scritte al mio imaginar a la santissima onda sacquistò e la \"\n",
            "Epoch 71/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.9541 - acc: 0.2234\n",
            "Dante dice: \"riguardar la superna costume la mia pervenne ornata e io e di qua dove già si fa grazioso e giugne polissena traditor che mi volsi \"\n",
            "Epoch 72/500\n",
            "97393/97393 [==============================] - 33s 336us/step - loss: 3.9380 - acc: 0.2241\n",
            "Dante dice: \"saliri di chiappa in sua mortalità o sementa matte e io a la sua strema caritate l mio gradir laltra la rosa sempiterna che la \"\n",
            "Epoch 73/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 3.9200 - acc: 0.2277\n",
            "Dante dice: \"nascimenti si sostegna parole nacqui e io è carbon che tante solere e di parlasia ferrati incontro mio a questo che coverto sarte che l \"\n",
            "Epoch 74/500\n",
            "97393/97393 [==============================] - 33s 334us/step - loss: 3.9033 - acc: 0.2299\n",
            "Dante dice: \"sigillo di sua danza e crescémi vita e e iustinïano che la zucca però de le sue pitture certe labi esperïenza parlavi laccoglienza impediti e \"\n",
            "Epoch 75/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 3.8894 - acc: 0.2312\n",
            "Dante dice: \"paleo ma diversi fiato e si converrebbe al mio pregio or si discernea palese le sue orme si disnodi e varcheresti eclissi e le ciglia \"\n",
            "Epoch 76/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.8707 - acc: 0.2342\n",
            "Dante dice: \"curar féne ello bestie secreta accoglie ma guardò rotare che mostrò che l suo fatale sian suo passo dipartille e scura e colà che dovresti \"\n",
            "Epoch 77/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 3.8541 - acc: 0.2365\n",
            "Dante dice: \"rifiuto nascesti schivi osanna                                                                                                                                                    \"\n",
            "Epoch 78/500\n",
            "97393/97393 [==============================] - 32s 328us/step - loss: 3.8441 - acc: 0.2379\n",
            "Dante dice: \"lento vegn fattore oltraggio dicerolti la mente e l mio disposizion l monte non che sempre e lusato non non liste e e per la \"\n",
            "Epoch 79/500\n",
            "97393/97393 [==============================] - 33s 334us/step - loss: 3.8290 - acc: 0.2388\n",
            "Dante dice: \"fiacco e io veggendola e è che la schiena larticular che a la belletta somigliante or nondimeno èli                                                  \"\n",
            "Epoch 80/500\n",
            "97393/97393 [==============================] - 32s 328us/step - loss: 3.8103 - acc: 0.2427\n",
            "Dante dice: \"dovria te e soldanieri in che segò grado che piagne volontà mai ne le sue grotte di quel che si fece e si disse e \"\n",
            "Epoch 81/500\n",
            "97393/97393 [==============================] - 33s 336us/step - loss: 3.7934 - acc: 0.2447\n",
            "Dante dice: \"come l duca mio forti là dove laffezion merta vapor i diavol viso e si riveggia a che facesti per pentimento che rugiada e la \"\n",
            "Epoch 82/500\n",
            "97393/97393 [==============================] - 33s 335us/step - loss: 3.7774 - acc: 0.2444\n",
            "Dante dice: \"bresciani e bergamaschi col nella tuo l muto de motti e l suo diretri pusillo a consolar le sue parole essenti un giro e che \"\n",
            "Epoch 83/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 3.7635 - acc: 0.2483\n",
            "Dante dice: \"lapparenza e l buon maestro e io chavea tu non è suo cura e si fa guance che lavar le sue magnificenze conosciute u saddua \"\n",
            "Epoch 84/500\n",
            "97393/97393 [==============================] - 33s 334us/step - loss: 3.7495 - acc: 0.2492\n",
            "Dante dice: \"sentivano andar è donna e se tu non so foglia accline la scoglio e l buon maestro chadice e roratelo o grando di san prete \"\n",
            "Epoch 85/500\n",
            "97393/97393 [==============================] - 32s 325us/step - loss: 3.7383 - acc: 0.2514\n",
            "Dante dice: \"reale velata donna risponder si schiude lalto chiude non altrimenti e da lor merto e preme e poi sapprezza nel nvii                             \"\n",
            "Epoch 86/500\n",
            "97393/97393 [==============================] - 33s 336us/step - loss: 3.7258 - acc: 0.2542\n",
            "Dante dice: \"doloroso seguitata e raccogli e proenza le sue parole stesse a dio che scommettendo renduta e a alma trovò e l popol gora ritorna a \"\n",
            "Epoch 87/500\n",
            "97393/97393 [==============================] - 32s 332us/step - loss: 3.7062 - acc: 0.2571\n",
            "Dante dice: \"le ciglia così parlommi e io ti menavano                                                                                                                        \"\n",
            "Epoch 88/500\n",
            "97393/97393 [==============================] - 32s 325us/step - loss: 3.6964 - acc: 0.2576\n",
            "Dante dice: \"vedersi rai che non può soffrir che n sua strada onde virtüalmente che la freddura conchiusa bestemmiavano nuvol mettere in campagnatico gissi al mio viso \"\n",
            "Epoch 89/500\n",
            "97393/97393 [==============================] - 33s 334us/step - loss: 3.6856 - acc: 0.2591\n",
            "Dante dice: \"mar si rauna e                                           \"\n",
            "Epoch 90/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 3.6747 - acc: 0.2611\n",
            "Dante dice: \"silvano a memoria altri attorti dammirazion di un dentro al viso mio gelato e quel che tobia posse se torto e l gelso diventò vermiglio \"\n",
            "Epoch 91/500\n",
            "97393/97393 [==============================] - 33s 340us/step - loss: 3.6579 - acc: 0.2624\n",
            "Dante dice: \"trade e farsalia rammarca van fuggita agogna e che non è di abito sperne ogne livore sparso di sua bestialitate coronati lalto fossa nettare quando \"\n",
            "Epoch 92/500\n",
            "97393/97393 [==============================] - 32s 326us/step - loss: 3.6397 - acc: 0.2647\n",
            "Dante dice: \"per tante nascimenti non landar squilla di terra che tu stolto discolpi sé vali e l fiele e a lor cantor che l uomini ferisse \"\n",
            "Epoch 93/500\n",
            "97393/97393 [==============================] - 32s 328us/step - loss: 3.6300 - acc: 0.2660\n",
            "Dante dice: \"lorizzonta e quel savio verbo e sindraca larcano a che dimostri luoghi ponno dinanzi a la sua anca di che in smalto gianni osanna o \"\n",
            "Epoch 94/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.6224 - acc: 0.2672\n",
            "Dante dice: \"rio fenestra era l triforme suono del mio viso che l sabbion guardando la talamone e rimirando ammuta o superinfusa gratïa deï sicut sunt trarria \"\n",
            "Epoch 95/500\n",
            "97393/97393 [==============================] - 32s 325us/step - loss: 3.6080 - acc: 0.2694\n",
            "Dante dice: \"padre potrete su che la gente saria lami che la testa inghirlanda sofferto e donno accesi con retrosi dacqua non vaccorgete che la groppa mi \"\n",
            "Epoch 96/500\n",
            "97393/97393 [==============================] - 33s 339us/step - loss: 3.5984 - acc: 0.2715\n",
            "Dante dice: \"pelle sciolte                                                                                                                                                                  \"\n",
            "Epoch 97/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.5824 - acc: 0.2734\n",
            "Dante dice: \"catona al sonar e l mondo suo trasse e quindi andi buccia cura fece state e giugner le labbra                                           \"\n",
            "Epoch 98/500\n",
            "97393/97393 [==============================] - 32s 326us/step - loss: 3.5788 - acc: 0.2732\n",
            "Dante dice: \"ricevuto così si tolse a le sue guance e è amara o poco or ti vedessi che per giudei pesa al mio che volontier poeti \"\n",
            "Epoch 99/500\n",
            "97393/97393 [==============================] - 32s 330us/step - loss: 3.5639 - acc: 0.2767\n",
            "Dante dice: \"sentenza e dimando e l mio maestro e l duca mio veggio il mio dovere anzi che sinfutura la mia pecca che lavina lor letizia \"\n",
            "Epoch 100/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.5516 - acc: 0.2771\n",
            "Dante dice: \"là ve l foco catalan che la gente e l ciel del mondo del runciglio mio pensava nel qual si ralligna così mincrebbe e graffiati \"\n",
            "Epoch 101/500\n",
            "97393/97393 [==============================] - 33s 343us/step - loss: 3.5431 - acc: 0.2792\n",
            "Dante dice: \"fessa che mi rivolsi così oppone e io mi paia a tagliar io l duca mio distese e l nuovo si partìne poeti onde vince \"\n",
            "Epoch 102/500\n",
            "97393/97393 [==============================] - 32s 325us/step - loss: 3.5296 - acc: 0.2827\n",
            "Dante dice: \"contenne e anima donato che si fa intanto appressa laceto e l fiele e                       \"\n",
            "Epoch 103/500\n",
            "97393/97393 [==============================] - 32s 328us/step - loss: 3.5215 - acc: 0.2825\n",
            "Dante dice: \"vani che quel dunacqua che farem le reni püerili che l suo cerebro aspetto non mi corse che regni che fuor di mille punte non \"\n",
            "Epoch 104/500\n",
            "97393/97393 [==============================] - 32s 330us/step - loss: 3.5131 - acc: 0.2829\n",
            "Dante dice: \"ragionare là giù e potean quelle genti a che di rose infallibil menzogna meglio a palme nodo vibra e mossa il freno e tien le \"\n",
            "Epoch 105/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 3.4948 - acc: 0.2856\n",
            "Dante dice: \"laugello intra dirti chi avea locchio e laltre sali almen sua cangiata more sì che tu si potien cessò ad ogn biade solingo chesser mi \"\n",
            "Epoch 106/500\n",
            "97393/97393 [==============================] - 33s 338us/step - loss: 3.4884 - acc: 0.2877\n",
            "Dante dice: \"si mprenti invaghito io vidi uscimmo e come langue creato a la milizia che l preterito disir la chiesa abbrusciato si tolse a lassetate rote \"\n",
            "Epoch 107/500\n",
            "97393/97393 [==============================] - 32s 326us/step - loss: 3.4778 - acc: 0.2877\n",
            "Dante dice: \"congiungi se l cortese cerbero monte dal salmo delectasti elli mi ritene così si sarian tue guida e torni detterno poco saper che tu caschi \"\n",
            "Epoch 108/500\n",
            "97393/97393 [==============================] - 32s 330us/step - loss: 3.4685 - acc: 0.2892\n",
            "Dante dice: \"che si pente ricordivi si ricorda si parea doppia nchiese e io crastino là ve la pïo delezïone quando percotendo non si maravigliar parsi la \"\n",
            "Epoch 109/500\n",
            "97393/97393 [==============================] - 32s 329us/step - loss: 3.4577 - acc: 0.2916\n",
            "Dante dice: \"buono e nel mondo errante che si prenda come vogliate lamagna facevan ascoltando passi luca fedeli che a la cintola e che la brigata di \"\n",
            "Epoch 110/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.4489 - acc: 0.2912\n",
            "Dante dice: \"peregrin che misuratamente in casa stava e fissi e non troverai quelle membri ricenti e diversi e e arsi sentia si rispondo e sì chadopera \"\n",
            "Epoch 111/500\n",
            "97393/97393 [==============================] - 33s 337us/step - loss: 3.4367 - acc: 0.2950\n",
            "Dante dice: \"nocchiere e fero nomar quella che la detta virtute corra ei morisse in quel che si nomava ma distinse e rade a terra abbraccia a \"\n",
            "Epoch 112/500\n",
            "97393/97393 [==============================] - 32s 325us/step - loss: 3.4282 - acc: 0.2962\n",
            "Dante dice: \"muovere e contro al pastor del fiero divino impediva la fronte veggendo non a lei taglia nascere tu passando che l duca mio l lingua \"\n",
            "Epoch 113/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.4197 - acc: 0.2978\n",
            "Dante dice: \"sicuramente allor disvelta secoli e l mio duca a che la chiesa morrocco e povertà e quel conoscitor a la francesca fuggir sente né circe \"\n",
            "Epoch 114/500\n",
            "97393/97393 [==============================] - 32s 328us/step - loss: 3.4106 - acc: 0.2981\n",
            "Dante dice: \"medea si fé vino aveva poco dora e a fermi obietto e va inforcar che a me stesso de la sannella cuopre lo duca che \"\n",
            "Epoch 115/500\n",
            "97393/97393 [==============================] - 32s 332us/step - loss: 3.4047 - acc: 0.2987\n",
            "Dante dice: \"degno e più che riguardai com io dubbiava per la sagrestia di sua madre venendo mi corse ond io che pastori a lui e pirro \"\n",
            "Epoch 116/500\n",
            "97393/97393 [==============================] - 33s 336us/step - loss: 3.3935 - acc: 0.3002\n",
            "Dante dice: \"dirmi ali allungata unì a te di neri sustanzïal che simborga di miei sello che si tange dal telo dercule che livïo lieti la becchetto \"\n",
            "Epoch 117/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 3.3846 - acc: 0.3018\n",
            "Dante dice: \"lasso là giù negletta portar della ogne dimostrazion che valore di tevero là piangëa rabano che la innamora e poi che si ricrea le gambe \"\n",
            "Epoch 118/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.3755 - acc: 0.3050\n",
            "Dante dice: \"fu bisava al suoi avversaro de le tempie del fondo riformossi a tuo rispuoser la barba onde vien pianto ma non seguon amendue seppe donati \"\n",
            "Epoch 119/500\n",
            "97393/97393 [==============================] - 32s 325us/step - loss: 3.3656 - acc: 0.3058\n",
            "Dante dice: \"e non trarrei però che vive e poi che tu si fée non produce lena ell se l trasmutar ditemi stesso disposta poi chamendue l \"\n",
            "Epoch 120/500\n",
            "97393/97393 [==============================] - 33s 336us/step - loss: 3.3618 - acc: 0.3062\n",
            "Dante dice: \"gioconde che la cervice e tronco dunacqua che veggion lalte navicella ancor che l veltro tenete lo mondo senta che continüò dal mio si rinselva \"\n",
            "Epoch 121/500\n",
            "97393/97393 [==============================] - 33s 334us/step - loss: 3.3488 - acc: 0.3080\n",
            "Dante dice: \"diretto raggiava e ferro tirato in sua follia ficca luoghi testando in dietro ed ecco non minori in bastardi da che la sua vita postrema \"\n",
            "Epoch 122/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.3320 - acc: 0.3096\n",
            "Dante dice: \"popolo e falde chi mi pregasti verga discioglie esser differenti sue donne etade o lampo che tu balbuzïendo ontoso cose chuscir fieno e l tripudio \"\n",
            "Epoch 123/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.3322 - acc: 0.3116\n",
            "Dante dice: \"in terra in terra fumma e tremando che piangëa sì che purga e se desti la sampogna feste che ricordarsi e diss io non è \"\n",
            "Epoch 124/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.3268 - acc: 0.3113\n",
            "Dante dice: \"pesci venire e quindi ritenne che si pigli miei e a la sua testa si riluce ambo lora alza le braccia de la trista cani \"\n",
            "Epoch 125/500\n",
            "97393/97393 [==============================] - 32s 328us/step - loss: 3.3200 - acc: 0.3116\n",
            "Dante dice: \"fastidiosi lucida ma poi il suo nome che si soccorse di dramma di mar lomo sì cominciò il saladino e corrono a verona del mondo \"\n",
            "Epoch 126/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.3033 - acc: 0.3164\n",
            "Dante dice: \"singrada e si gittar ombre che la campagna del vermigli di glorïoso malebranche quando geli cristo non si mostra nemica la mente del mio volto \"\n",
            "Epoch 127/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 3.3023 - acc: 0.3150\n",
            "Dante dice: \"sicuramente avviso e sire o differenti mie tempre loquela nesce ma quale e di là dal trïunfo che n sé medesmo ritornò sicuramente e e \"\n",
            "Epoch 128/500\n",
            "97393/97393 [==============================] - 32s 332us/step - loss: 3.2878 - acc: 0.3177\n",
            "Dante dice: \"lappago il mio vermiglio giù per secoli giaciuto che non posso eletto a la tua caritate si dome se talvolta mi sigillava e quei il \"\n",
            "Epoch 129/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 3.2807 - acc: 0.3194\n",
            "Dante dice: \"suole in ponte ad laguglie si stende a dilatarsi e de la mente aduno di muse e ciascheduno diche scorge la bocca bugiarda sabbandona e \"\n",
            "Epoch 130/500\n",
            "97393/97393 [==============================] - 33s 335us/step - loss: 3.2733 - acc: 0.3192\n",
            "Dante dice: \"cerchi ancora montemalo e l grifone mio pinta in sé scabbia che mutò roma per venire quasi suonan ora siam ridon le sue orme e \"\n",
            "Epoch 131/500\n",
            "97393/97393 [==============================] - 32s 334us/step - loss: 3.2640 - acc: 0.3227\n",
            "Dante dice: \"attendi guardi non si paresse ragionamenti remo teco danzando mhanno è nome onesta imposto a minòs che l barattier seppi e cardinali ite e come \"\n",
            "Epoch 132/500\n",
            "97393/97393 [==============================] - 32s 324us/step - loss: 3.2577 - acc: 0.3211\n",
            "Dante dice: \"sue omeri campagna sofferto ma come che la mia giro non lo uom grame e certa seguio e la mente tua l suo seguace èe \"\n",
            "Epoch 133/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.2475 - acc: 0.3242\n",
            "Dante dice: \"lavarizia di sua distanza le mpegolate cambiaro e lucenti ad lessenza incontro al folle levato non è che la mal sensi e dopo le sue \"\n",
            "Epoch 134/500\n",
            "97393/97393 [==============================] - 32s 330us/step - loss: 3.2464 - acc: 0.3243\n",
            "Dante dice: \"scendete la donna dove mi confuse panni dal fil a che luniverso a me si spazia posasi sì che questo troverai sé che moia del \"\n",
            "Epoch 135/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.2377 - acc: 0.3251\n",
            "Dante dice: \"giuso e per igne e torto a la sua madre mi fa intanto che rimira tali che la pastura mi percosse quand io verranno e \"\n",
            "Epoch 136/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.2259 - acc: 0.3272\n",
            "Dante dice: \"e diracundia van sorde partorisce                                                                                                                                             \"\n",
            "Epoch 137/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.2205 - acc: 0.3278\n",
            "Dante dice: \"gemme coltre che l ciel che mera rossa rotto queste sappiendo disse convienmi lho colà che si converria frode eravamo e si fe e l \"\n",
            "Epoch 138/500\n",
            "97393/97393 [==============================] - 33s 334us/step - loss: 3.2131 - acc: 0.3289\n",
            "Dante dice: \"volgemmo rimembrar mi disse trovar lenta e parole a me che l discreto onde vi fé veloci udito medesmi io pugliese e salvatico sinurba e \"\n",
            "Epoch 139/500\n",
            "97393/97393 [==============================] - 33s 336us/step - loss: 3.2052 - acc: 0.3298\n",
            "Dante dice: \"mondo longobardo sesta la brenta di quei adamo e avarizia sanza polpe e la trista giunta si dotar e vidile principio e menommi ad sopra \"\n",
            "Epoch 140/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 3.1978 - acc: 0.3308\n",
            "Dante dice: \"lappago il core che l gelata selvaggio usurpa che la strozza mi percosse così in ragione sannoda incarcerato e cherco in qual la poggio mi \"\n",
            "Epoch 141/500\n",
            "97393/97393 [==============================] - 33s 335us/step - loss: 3.1939 - acc: 0.3322\n",
            "Dante dice: \"mio pellicano e quel zita tardo e prima che l mirava del suo sinistro turgide                               \"\n",
            "Epoch 142/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.1831 - acc: 0.3332\n",
            "Dante dice: \"fuma dirizzami di sangue uscimmo lagrimando a pirro ma scimia sé che me fur que stola messi ve libente e io maestro mio fa sarmasse \"\n",
            "Epoch 143/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.1744 - acc: 0.3352\n",
            "Dante dice: \"dimmi di sigieri che sì che lavea fossero ingiustamente l gustar e da la mente sempiterna che l spirito suo saputa ché dolce voce in \"\n",
            "Epoch 144/500\n",
            "97393/97393 [==============================] - 32s 328us/step - loss: 3.1741 - acc: 0.3347\n",
            "Dante dice: \"a la calca lacca altrimenti di la calca si schiarì sì a la tua narrazion buia vulcano lanimo mostrava se si cuopre e prenderai a \"\n",
            "Epoch 145/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.1674 - acc: 0.3359\n",
            "Dante dice: \"napoli cassio la donna dove salendo sù torni ond io vidi serafico e quelle prime intento porte e blande traditor a le poste de sé \"\n",
            "Epoch 146/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.1570 - acc: 0.3387\n",
            "Dante dice: \"am i maschi varo ond ei seguiva poi come dietro sì che lagrimar risponda o ridure e che l suo parvenza e vinta allor soavemente \"\n",
            "Epoch 147/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.1499 - acc: 0.3398\n",
            "Dante dice: \"parlerei a me saper disse fieramente veduta stanca e trapassando giù voli lume colpe navea unghiate le rivolse che lossa quali aspettando se piangea od \"\n",
            "Epoch 148/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.1516 - acc: 0.3387\n",
            "Dante dice: \"ancor rotta i patrïa oh intra la selva e là sù a ballo acquisto esser bestia che lumana bontade e io e late e rubicante \"\n",
            "Epoch 149/500\n",
            "97393/97393 [==============================] - 33s 336us/step - loss: 3.1436 - acc: 0.3415\n",
            "Dante dice: \"singrada in donna e poi a sua sospeccion talvolta mi gittai come tristi mi lagnerà se seppellite convienmi in dietro in soglia domanda moralità brami \"\n",
            "Epoch 150/500\n",
            "97393/97393 [==============================] - 31s 323us/step - loss: 3.1334 - acc: 0.3421\n",
            "Dante dice: \"ritorte così benedicendomi sinsempra                                                                                                                                                    \"\n",
            "Epoch 151/500\n",
            "97393/97393 [==============================] - 32s 333us/step - loss: 3.1245 - acc: 0.3442\n",
            "Dante dice: \"vïaggio sentire nebber sicuro per te mi travagliava di viver che e e quattro stelle ma si distende a rimirar chi si ricoperse e come \"\n",
            "Epoch 152/500\n",
            "97393/97393 [==============================] - 31s 322us/step - loss: 3.1193 - acc: 0.3450\n",
            "Dante dice: \"rimembra e munta scarsi a la sua risposta e corte a la mente bianca il duca e che a gradire che l male e coltel \"\n",
            "Epoch 153/500\n",
            "97393/97393 [==============================] - 33s 337us/step - loss: 3.1152 - acc: 0.3467\n",
            "Dante dice: \"e certa riverso e io che intrar nel punga stesse che fa l mondo girone penelopè questa metropolitano duce che sua landa chello vassi a \"\n",
            "Epoch 154/500\n",
            "35712/97393 [==========>...................] - ETA: 19s - loss: 3.0469 - acc: 0.3574Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CVgScJ9NIvs3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se stai usando una GPU che supporta la tecnologia CUDA, sul tuo computer o con Google Colaboratory, l'addestramento per 500 epoche dovrebbe richiedere un paio di ore, se non vuoi aspettare puoi ridurre il numero di epoche a non meno di 100 oppure importare il modello che ho già addestrato eseguendo il codice qui sotto."
      ]
    },
    {
      "metadata": {
        "id": "QCsEOmaWlSnQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('dante2.h5')  # creates a HDF5 file 'my_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VXGyYIlV7ppT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c89ec385-901c-416e-c7af-2e4856a1164a"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(X,y)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97393/97393 [==============================] - 64s 657us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.1553208158663284, 0.5180454447481608]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "U42_UVaeJPzS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve\n",
        "from keras.models import load_model\n",
        "\n",
        "model_file = \"dante.h5\"\n",
        "\n",
        "# Scarichiamo il modello preaddestrato dalla repo github del corso\n",
        "model_url = \"https://github.com/ProfAI/nlp00/raw/master/9%20-%20Reti%20Ricorrenti%20e%20Text%20Generation/model/dante.h5\"\n",
        "urlretrieve(model_url, model_file)\n",
        "\n",
        "# carichiamo il modello\n",
        "model = load_model(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eNl2HraMK6YQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Proviamo a dialogare con il nostro Dante-bot, il testo che inseriremo verrà usato come seed per la generazione di nuovo testo in stile dantesco."
      ]
    },
    {
      "metadata": {
        "id": "MVMfMusoK_0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d826bf37-a7e7-47e7-d01b-0d9eff733b09"
      },
      "cell_type": "code",
      "source": [
        "seed = \"\"\n",
        "\n",
        "while(seed!=\"ciao\"):\n",
        "  seed = input(\"Io: \")\n",
        "  generated = generate(seed=seed)\n",
        "  print(\"Dante: \"+generated)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Io: ciao\n",
            "Dante: e la occhi e che e che e che e che e che e che e che e che e che e che e che \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}