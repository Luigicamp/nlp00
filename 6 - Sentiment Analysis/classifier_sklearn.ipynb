{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier_sklearn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/nlp00/blob/master/6%20-%20Sentiment%20Analysis/classifier_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SD7bU28fId0p"
      },
      "cell_type": "markdown",
      "source": [
        "# Creare un classificatore con Scikit-learn"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vMyeO5ZJIh7x"
      },
      "cell_type": "markdown",
      "source": [
        "## Procuriamoci il dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tDQc-LaEgCyH",
        "outputId": "2d9d22f2-cc91-4693-af32-0243e3943511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-15 15:53:33--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  22.7MB/s    in 4.0s    \n",
            "\n",
            "2019-04-15 15:53:37 (20.3 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gdKW07o6hErd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -xzf aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-c7lE6SNs8ka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Usiamo le features precalcolate"
      ]
    },
    {
      "metadata": {
        "id": "YL3ockmms8kb",
        "colab_type": "code",
        "colab": {},
        "outputId": "a4f960a3-7600-4e30-ce62-35a1ee3cc087"
      },
      "cell_type": "code",
      "source": [
        "dataset = load_svmlight_file(\"aclImdb/train/labeledBow.feat\")\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<25000x89527 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 3456685 stored elements in Compressed Sparse Row format>,\n",
              " array([9., 7., 9., ..., 4., 2., 2.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "D8J85a1ms8ke",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "\n",
        "def get_xy(file, dictsize=5000, binary=True):\n",
        "        \n",
        "    MAX_DICTSIZE = 89522\n",
        "        \n",
        "    if(dictsize>MAX_DICTSIZE):\n",
        "        dict_size = MAX_DICTSIZE\n",
        "    \n",
        "    dataset = load_svmlight_file(file)\n",
        "    X = dataset[0].todense()\n",
        "    X = np.array(X[:,:dictsize])\n",
        "    y = dataset[1]\n",
        "    \n",
        "    if(binary):\n",
        "        y[y<=5] = 0\n",
        "        y[y>5] = 1\n",
        "    #y = np.array(dataset[:,-1]).flatten()\n",
        "        \n",
        "    return (X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "r-b6_bSiK1TJ",
        "colab": {},
        "outputId": "5ff8bdfe-0e52-48aa-bc6b-76c51d4cf23c"
      },
      "cell_type": "code",
      "source": [
        "X_train, y_train = get_xy(\"aclImdb/train/labeledBow.feat\")\n",
        "X_test, y_test = get_xy(\"aclImdb/test/labeledBow.feat\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 5000)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XiFrYliBs8kk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_test = ss.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U0ExqABCs8ko",
        "colab_type": "code",
        "colab": {},
        "outputId": "c98c2d2c-40f6-4044-a0a1-e12e300e549e"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(C=0.001)\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "rMPXYYH7s8kq",
        "colab_type": "code",
        "colab": {},
        "outputId": "4325c955-f83d-46d6-e3ac-843ab838bb99"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "train_pred = lr.predict(X_train) \n",
        "train_pred_proba = lr.predict_proba(X_train)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "train_loss = log_loss(y_train, train_pred_proba)\n",
        "\n",
        "test_pred = lr.predict(X_test)\n",
        "test_pred_proba = lr.predict_proba(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "test_loss = log_loss(y_test, test_pred_proba)\n",
        "\n",
        "print(\"Train Accuracy %.4f - Train Loss %.4f\" % (train_accuracy, train_loss)) \n",
        "print(\"Test Accuracy %.4f - Test Loss %.4f\" % (test_accuracy, test_loss)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy 0.9440 - Train Loss 0.1978\n",
            "Test Accuracy 0.8776 - Test Loss 0.3126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kgSwfbcAs8kt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Estraiamo le features"
      ]
    },
    {
      "metadata": {
        "id": "2c7la1dIt_wk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c8835f1a-79b7-47e7-d392-c4e304024579"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "BRbilnAos8ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "3b37588e-796a-4df1-e6ff-00b441ffef5f"
      },
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from os import listdir\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "dictionary = set({})\n",
        "\n",
        "dataset = []\n",
        "\n",
        "for file in listdir(\"aclImdb/train/pos\"):\n",
        "    review_file = open(\"aclImdb/train/pos/\"+file)\n",
        "    review = review_file.read()\n",
        "    \n",
        "    print(review)\n",
        "    \n",
        "    review = review.lower()\n",
        "    review = tokenizer.tokenize(review)\n",
        "    \n",
        "    words={}\n",
        "    \n",
        "    for word in review:\n",
        "      if(word not in stopwords):\n",
        "          words[word] = words[word]+1 if word in words.keys() else 1\n",
        "          dictionary.add(word)\n",
        "        \n",
        "    break\n",
        "    \n",
        "print(words)\n",
        "print(dictionary)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The 1967 In Cold Blood was perhaps more like \"the real thing\" (Think about it: would we really want to see the real thing?), but it was black and white in a color world, and a lot of people didn't even know what it was, and there was an opportunity to remake it for television. Plus, if you remake it, you can show some stuff not shown in the original. The book In Cold Blood by Truman Capote was the first \"nonfiction novel\". Truman's book was in fact not 100% true to the real story. I thought the Canadian location sufficed for Kansas pretty much for a TV movie. Look for the elements of sex, drugs and rock 'n' roll: Dick's womanizing, Perry being an aspirin junkie, Perry playing blues guitar.\n",
            "{'1967': 1, 'cold': 2, 'blood': 2, 'perhaps': 1, 'like': 1, 'real': 3, 'thing': 2, 'think': 1, 'would': 1, 'really': 1, 'want': 1, 'see': 1, 'black': 1, 'white': 1, 'color': 1, 'world': 1, 'lot': 1, 'people': 1, 'even': 1, 'know': 1, 'opportunity': 1, 'remake': 2, 'television': 1, 'plus': 1, 'show': 1, 'stuff': 1, 'shown': 1, 'original': 1, 'book': 2, 'truman': 2, 'capote': 1, 'first': 1, 'nonfiction': 1, 'novel': 1, 'fact': 1, '100': 1, 'true': 1, 'story': 1, 'thought': 1, 'canadian': 1, 'location': 1, 'sufficed': 1, 'kansas': 1, 'pretty': 1, 'much': 1, 'tv': 1, 'movie': 1, 'look': 1, 'elements': 1, 'sex': 1, 'drugs': 1, 'rock': 1, 'n': 1, 'roll': 1, 'dick': 1, 'womanizing': 1, 'perry': 2, 'aspirin': 1, 'junkie': 1, 'playing': 1, 'blues': 1, 'guitar': 1}\n",
            "{'black', 'television', 'kansas', 'think', 'canadian', 'first', 'true', 'junkie', 'like', 'novel', 'thought', 'rock', 'aspirin', 'even', 'real', 'nonfiction', 'movie', 'womanizing', 'much', 'plus', 'book', 'original', 'pretty', 'really', 'want', 'fact', 'guitar', 'capote', 'world', 'location', 'playing', 'show', 'would', 'remake', 'cold', 'truman', 'sufficed', 'opportunity', 'tv', 'drugs', 'know', 'white', 'thing', 'see', 'dick', 'roll', 'blood', 'elements', 'perry', 'color', 'stuff', 'story', 'look', 'lot', 'shown', 'blues', 'people', '100', 'sex', 'perhaps', '1967', 'n'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vt6648bEs8kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "def get_xy(files_path, labels=[\"pos\",\"neg\"]):\n",
        "    \n",
        "    \n",
        "    label_map = {labels[0]:1, labels[1]:0}\n",
        "    \n",
        "    reviews = []\n",
        "    y = []\n",
        "    \n",
        "    for label in labels:\n",
        "      path = files_path+label\n",
        "      for file in listdir(path):\n",
        "        review_file = open(path+\"/\"+file)\n",
        "        review = review_file.read()    \n",
        "        \n",
        "        reviews.append(review)\n",
        "        y.append(label_map[label])\n",
        "        \n",
        "    reviews, y = shuffle(reviews,y)\n",
        "    \n",
        "    return(reviews,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NHlX51rNxU38",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reviews_train, y_train = get_xy(\"aclImdb/train/\")\n",
        "reviews_test, y_test = get_xy(\"aclImdb/test/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MffwVvQ3zweG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99a91847-577b-442e-e03f-6979cb106fa8"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow = CountVectorizer(max_features=5000)\n",
        "\n",
        "bow_train = bow.fit_transform(reviews_train)\n",
        "bow_test = bow.transform(reviews_test)\n",
        "\n",
        "X_train = bow_train.toarray()\n",
        "X_test = bow_test.toarray()\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "UzEYumlq2D0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "462e3b6a-76eb-4882-adfb-8955d41f319b"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_test = ss.transform(X_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "mkkLg-MX-zoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "a9520baf-abdb-4267-ade8-c3e67c2f2c2f"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(C=0.001)\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "y3IJDsVp-7PC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "105d9579-1b03-4117-c06e-39753f2b1d5a"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "train_pred = lr.predict(X_train) \n",
        "train_pred_proba = lr.predict_proba(X_train)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "train_loss = log_loss(y_train, train_pred_proba)\n",
        "\n",
        "test_pred = lr.predict(X_test)\n",
        "test_pred_proba = lr.predict_proba(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "test_loss = log_loss(y_test, test_pred_proba)\n",
        "\n",
        "print(\"Train Accuracy %.4f - Train Loss %.4f\" % (train_accuracy, train_loss)) \n",
        "print(\"Test Accuracy %.4f - Test Loss %.4f\" % (test_accuracy, test_loss)) "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy 0.9432 - Train Loss 0.1975\n",
            "Test Accuracy 0.8772 - Test Loss 0.3125\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}