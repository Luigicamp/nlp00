{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier_sklearn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/nlp00/blob/master/6%20-%20Sentiment%20Analysis/classifier_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SD7bU28fId0p"
      },
      "cell_type": "markdown",
      "source": [
        "# Creare un classificatore con Scikit-learn\n",
        "In questo notebook vedremo come creare un classificatore utilizzando scikit-learn. Lo scopo del nostro classificatore sarà quello di eseguire la **sentiment analysis** sull'IMDB movie reviews dataset, per classificare le recensioni di film come negative o positive."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vMyeO5ZJIh7x"
      },
      "cell_type": "markdown",
      "source": [
        "## Procuriamoci il dataset\n",
        "Cominciamo scaricando il dataset, esegui la cella di codice qui sotto se sei su Google Colab o se hai wget installato sul tuo computer, altrimenti puoi scaricare il dataset da [questo link](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tDQc-LaEgCyH",
        "outputId": "0924a7c2-2867-494d-aaa2-1ea17cca5bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-15 18:08:01--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  20.8MB/s    in 6.5s    \n",
            "\n",
            "2019-04-15 18:08:08 (12.4 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hG9mWOxNGYUM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "L'archivio è compresso in formato tar.gz, esegui la cella di codice qui sotto se sei su Colab o hai l'utility tar installata sul tuo PC (solitamente è installata di base su Linux/OsX) se sei su Windows puoi usare [7-zip](https://www.7-zip.org/) (può essere che anche winrar vada bene per estrarlo)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gdKW07o6hErd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -xzf aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pdxn7YG1G-Wb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se abbiamo estratto il dataset adesso avremo una cartella aclImdb con dentro diversi file e altre due cartelle, una con le recensioni per l'addestramento e una con le recensioni per il test. Il dataset ci fornisce il testo di ogni recensione, ognuna in un file txt differente, organizzate in cartelle corrispondenti al sentiment positivo/negativo.\n",
        "<br>\n",
        "Oltre a questo ci vengono forniti dei file .feat con le recensioni già codificate utilizzando il **bag of words**, cominciamo utilizzando questi file per creare un classificatore, dopo vedremo come codificare noi stessi le recensioni."
      ]
    },
    {
      "metadata": {
        "id": "-c7lE6SNs8ka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Usiamo le features precalcolate\n",
        "Le features sono codificate in formato LIBSVM, un formato utilizzato per codificare matrici sparse. Ogni riga rappresenta una recensione, il primo numero di ogni riga corrisponde al sentiment da 1 (molto scarso) a 9 (molto buono). Gli altri valori sono in formato chiave:valore, dove la chiave è l'indice della parola all'interno del dizionario (il file imdb.vocab) e il valore è il numero di volte che la parola in questione compare all'interno della frase.\n",
        "<br>\n",
        "Definiamo una funzione che partendo da questo file ci permetta di ottenere la matrice che ha per ogni riga la rappresentazione bag of words di ogni recensione e il vettore con il sentiment.\n",
        "<br>\n",
        "Per caricare un file in formato LIBSVM possiamo usare la funzione *load_svmlight_file* di sklearn, il suo output è una tupla con all'indice 0 la matrice sparsa e all'indice 1 il vettore con i target. Utilizziamo un parametro max_features per limitare il numero di parole da tenere come features, tra quelle più frequenti."
      ]
    },
    {
      "metadata": {
        "id": "D8J85a1ms8ke",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "\n",
        "def get_xy(file, max_features=5000, binary=True):\n",
        "        \n",
        "    DICTSIZE = 89522\n",
        "    \n",
        "    # Le parole nel dizionario sono 89522\n",
        "    # se viene inserito un numero maggiore\n",
        "    # come dimensione del dizionario, correggiamolo\n",
        "        \n",
        "    if(max_features>DICTSIZE):\n",
        "        max_features = DICTSIZE\n",
        "    \n",
        "    dataset = load_svmlight_file(file)\n",
        "    X = dataset[0].todense() # .todense() serve per convertire la matrice sparsa in densa\n",
        "    \n",
        "    X = np.array(X[:,:max_features])\n",
        "    y = dataset[1]\n",
        "    \n",
        "    if(binary):\n",
        "        y[y<=5] = 0 # se il punteggio è minore o uguale a 5 è una recensione negativa\n",
        "        y[y>5] = 1 # se il punteggio è maggiore di 5 è una recensione positiva\n",
        "        \n",
        "    return (X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzEZoj_VJnQZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Utilizziamo la funzione per creare gli array per l'addestramento e il test."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "r-b6_bSiK1TJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, y_train = get_xy(\"aclImdb/train/labeledBow.feat\")\n",
        "X_test, y_test = get_xy(\"aclImdb/test/labeledBow.feat\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MWzQeJBEJsiP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Standardizziamo il dataset utilizzando la classe *StandardScaler* di sklearn."
      ]
    },
    {
      "metadata": {
        "id": "XiFrYliBs8kk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_test = ss.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q2aCcPVCJztD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creiamo il nostro modello di regressione logistica."
      ]
    },
    {
      "metadata": {
        "id": "U0ExqABCs8ko",
        "colab_type": "code",
        "outputId": "c98c2d2c-40f6-4044-a0a1-e12e300e549e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(C=0.001) # C ci serve per ridurre l'overfitting "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "CwjKt_YwJ2lR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verifichiamo il risultato calcolando accuracy e log loss."
      ]
    },
    {
      "metadata": {
        "id": "rMPXYYH7s8kq",
        "colab_type": "code",
        "outputId": "4325c955-f83d-46d6-e3ac-843ab838bb99",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "train_pred = lr.predict(X_train) \n",
        "train_pred_proba = lr.predict_proba(X_train)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "train_loss = log_loss(y_train, train_pred_proba)\n",
        "\n",
        "test_pred = lr.predict(X_test)\n",
        "test_pred_proba = lr.predict_proba(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "test_loss = log_loss(y_test, test_pred_proba)\n",
        "\n",
        "print(\"Train Accuracy %.4f - Train Loss %.4f\" % (train_accuracy, train_loss)) \n",
        "print(\"Test Accuracy %.4f - Test Loss %.4f\" % (test_accuracy, test_loss)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy 0.9440 - Train Loss 0.1978\n",
            "Test Accuracy 0.8776 - Test Loss 0.3126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kgSwfbcAs8kt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Estraiamo le features\n",
        "Adesso proviamo a fare lo stesso, ma questa volta partendo dalle recensioni e codificandole noi stessi utilizzando il bag of words. Definiamo una funzione per leggere tutte le recensioni da tutti i files per poi ritornarle insieme al target corrispondente. Prima di ritornarle mescoliamo il dataset."
      ]
    },
    {
      "metadata": {
        "id": "Vt6648bEs8kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "def get_xy(files_path, labels=[\"pos\",\"neg\"]):\n",
        "    \n",
        "    \n",
        "    label_map = {labels[0]:1, labels[1]:0}\n",
        "    \n",
        "    reviews = []\n",
        "    y = []\n",
        "    \n",
        "    for label in labels:\n",
        "      path = files_path+label\n",
        "      for file in listdir(path):\n",
        "        review_file = open(path+\"/\"+file)\n",
        "        review = review_file.read()    \n",
        "        \n",
        "        reviews.append(review)\n",
        "        y.append(label_map[label])\n",
        "        \n",
        "    # la funzione shuffle di sklearn ci permette di\n",
        "    # mescolare più array allo stesso modo\n",
        "    \n",
        "    reviews, y = shuffle(reviews,y)\n",
        "    \n",
        "    return(reviews,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4KxQkTHMKxY9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Utilizziamo la funzione per ottenere le recensioni e il target in due liste."
      ]
    },
    {
      "metadata": {
        "id": "NHlX51rNxU38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6cfaf522-cd2b-42d8-a807-ab4b1182eea2"
      },
      "cell_type": "code",
      "source": [
        "reviews_train, y_train = get_xy(\"aclImdb/train/\")\n",
        "reviews_test, y_test = get_xy(\"aclImdb/test/\")\n",
        "\n",
        "print(\"Prima recensione del set di test\")\n",
        "print(reviews_test[0])\n",
        "print(\"Sentimeny: %d\" % y_test[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prima recensione del set di test\n",
            "One of the two Best Films of the year. A well filmed, well written, well put together film with an outstanding cast. Lau Ching Wan and his friends (Dayo Wong Chi Wa, Anthony Wong Chau Sun, Francis Ng Chun Yu, Jordan Chan Siu Chun, Cheung Man Tat) had great chemistry before the film and their friendship shows in their performances. Theresa Lee plays her comedic role well (Though much like a female version of Michael Wong, her gag seems to be the foreign born Chinese surrounded by native HKers.), and I found myself cheering for innovative explosive scenes, something I haven't done since 1. the fan boys took over alt.asian-movies and 2. John woo's Hardboiled. Sure the ending was expected, but I feel better cheering for cops than a bunch of young gang members. Highly enjoyable.\n",
            "Sentimeny: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l67_N8cVLL13",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adesso codifichiamo le recensioni, possiamo eseguire il bag of words con scikit-learn utilizzando la classe *CountVectorizer*, tramite il parametro *max_fetures* possiamo controllare il numero totale di features (e quindi di parole) da tenere, nel nostro caso teniamo soltanto le 5000 parole più frequenti."
      ]
    },
    {
      "metadata": {
        "id": "MffwVvQ3zweG",
        "colab_type": "code",
        "outputId": "99a91847-577b-442e-e03f-6979cb106fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow = CountVectorizer(max_features=5000)\n",
        "\n",
        "bow_train = bow.fit_transform(reviews_train)\n",
        "bow_test = bow.transform(reviews_test)\n",
        "\n",
        "X_train = bow_train.toarray()\n",
        "X_test = bow_test.toarray()\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "ZFVl1c97K3z4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adesso abbiamo i nostri array per addestramento e test ! Standardizziamoli utilizzando la classe *StandardScaler* di sklearn"
      ]
    },
    {
      "metadata": {
        "id": "UzEYumlq2D0D",
        "colab_type": "code",
        "outputId": "462e3b6a-76eb-4882-adfb-8955d41f319b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_test = ss.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nznJchb5L-zC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "e creiamo il modello di regressione logistica, cerchiamo di ridurre un probabile 'overfitting impostando il parametro C ad un valore piccolo."
      ]
    },
    {
      "metadata": {
        "id": "mkkLg-MX-zoJ",
        "colab_type": "code",
        "outputId": "a9520baf-abdb-4267-ade8-c3e67c2f2c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(C=0.001)\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "otjc9_kDMHxO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verifichiamo il risultato calcolando l'accuracy e la log loss."
      ]
    },
    {
      "metadata": {
        "id": "y3IJDsVp-7PC",
        "colab_type": "code",
        "outputId": "105d9579-1b03-4117-c06e-39753f2b1d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "train_pred = lr.predict(X_train) \n",
        "train_pred_proba = lr.predict_proba(X_train)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "train_loss = log_loss(y_train, train_pred_proba)\n",
        "\n",
        "test_pred = lr.predict(X_test)\n",
        "test_pred_proba = lr.predict_proba(X_test)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "test_loss = log_loss(y_test, test_pred_proba)\n",
        "\n",
        "print(\"Train Accuracy %.4f - Train Loss %.4f\" % (train_accuracy, train_loss)) \n",
        "print(\"Test Accuracy %.4f - Test Loss %.4f\" % (test_accuracy, test_loss)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy 0.9432 - Train Loss 0.1975\n",
            "Test Accuracy 0.8772 - Test Loss 0.3125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u6XSuNbsMe90",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Senza alcuna sorpresa, il risultato è lo stesso di prima, ma stavolta abbiamo fatto tutto noi :)."
      ]
    }
  ]
}