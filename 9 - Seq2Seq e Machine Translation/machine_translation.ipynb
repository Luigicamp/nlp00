{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/nlp00/blob/master/9%20-%20Seq2Seq%20e%20Machine%20Translation/machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PKRyLzAhw-IC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "3d36bb63-2cff-4c4d-8dce-c5a2dcc4c4ea"
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.manythings.org/anki/ita-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-19 17:55:58--  http://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3981147 (3.8M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "ita-eng.zip         100%[===================>]   3.80M  12.4MB/s    in 0.3s    \n",
            "\n",
            "2019-04-19 17:56:04 (12.4 MB/s) - ‘ita-eng.zip’ saved [3981147/3981147]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A4Se2U15xbB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e3050d18-f39c-45f4-f5d8-3ba5ebbf009c"
      },
      "cell_type": "code",
      "source": [
        "!unzip ita-eng.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mEeEpIPvxeKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "a71295e5-59b4-460a-eff0-ecbb82ca03fa"
      },
      "cell_type": "code",
      "source": [
        "with open(\"ita.txt\") as eng_ita_sents:\n",
        "  eng_ita_sents = eng_ita_sents.read().split(\"\\n\")\n",
        "\n",
        "print(\"%d esempi\\n\" % len(eng_ita_sents))\n",
        "  \n",
        "for i in range(5):\n",
        "  print(eng_ita_sents[i])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "321434 esempi\n",
            "\n",
            "Hi.\tCiao!\n",
            "Run!\tCorri!\n",
            "Run!\tCorra!\n",
            "Run!\tCorrete!\n",
            "Who?\tChi?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XcG3xVrXx5OO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "93b11548-650e-4971-8e13-689c8d0fe160"
      },
      "cell_type": "code",
      "source": [
        "eng_sents = []\n",
        "ita_sents = []\n",
        "\n",
        "for eng_ita_sent in eng_ita_sents:\n",
        "  eng_ita_sent = eng_ita_sent.split(\"\\t\")\n",
        "  if(len(eng_ita_sent)==2):\n",
        "    eng_sents.append(eng_ita_sent[0])\n",
        "    ita_sents.append(eng_ita_sent[1])\n",
        "\n",
        "print(eng_sents[:5])\n",
        "print(ita_sents[:5])      "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi.', 'Run!', 'Run!', 'Run!', 'Who?']\n",
            "['Ciao!', 'Corri!', 'Corra!', 'Correte!', 'Chi?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A2QVbsXpVoCI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_samples = 10000\n",
        "\n",
        "eng_sents = eng_sents[:max_samples]\n",
        "ita_sents = ita_sents[:max_samples]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LuQjnKmTzNWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a7786b15-1c63-4d86-9bff-9c1cfa4dd734"
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'[^\\w\\s]','',text)\n",
        "  text = \"SOS \"+text+\" EOS\"\n",
        "  return text\n",
        "\n",
        "\n",
        "ita_sents = [preprocess(ita_sent) for ita_sent in ita_sents]\n",
        "eng_sents = [preprocess(eng_sent) for eng_sent in eng_sents]\n",
        "\n",
        "print(eng_sents[:5])\n",
        "print(ita_sents[:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SOS hi EOS', 'SOS run EOS', 'SOS run EOS', 'SOS run EOS', 'SOS who EOS']\n",
            "['SOS ciao EOS', 'SOS corri EOS', 'SOS corra EOS', 'SOS correte EOS', 'SOS chi EOS']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P23dJENI2Zx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ad86230a-575e-4c3f-b245-40a6786ae00b"
      },
      "cell_type": "code",
      "source": [
        "def get_dictionary(sents):\n",
        "  \n",
        "  dictionary = set({})\n",
        "  \n",
        "  for sent in sents:\n",
        "    dictionary|=set(sent.split())\n",
        "    \n",
        "  return list(dictionary)\n",
        "\n",
        "\n",
        "eng_dict = get_dictionary(eng_sents)\n",
        "ita_dict = get_dictionary(ita_sents)\n",
        "\n",
        "print(\"%d parole nel dizionario inglese\" % len(eng_dict))\n",
        "print(\"%d parole nel dizionario italiano\" % len(ita_dict))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1412 parole nel dizionario inglese\n",
            "3571 parole nel dizionario italiano\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8AdVrq4A5DQC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eng_dict_rev = {k: v for k, v in zip(eng_dict, range(len(eng_dict)))}\n",
        "ita_dict_rev = {k: v for k, v in zip(ita_dict, range(len(ita_dict)))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MR58SPEq3uNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ab386388-25d9-4adf-d7e3-6c979a17f019"
      },
      "cell_type": "code",
      "source": [
        "def encode(sents, dict_rev):\n",
        "  \n",
        "  sents_enc = []\n",
        "  \n",
        "  for sent in sents:\n",
        "    sents_enc.append([dict_rev[word] for word in sent.split()])\n",
        "    \n",
        "  return sents_enc\n",
        "\n",
        "X_encoder = encode(ita_sents, ita_dict_rev)\n",
        "X_decoder = encode(eng_sents, eng_dict_rev)\n",
        "\n",
        "Y = []\n",
        "\n",
        "for x in X_decoder:\n",
        "  Y.append(x[1:])\n",
        "\n",
        "print(eng_sents[:10])\n",
        "print(X_decoder[:10])\n",
        "print(Y[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SOS hi EOS', 'SOS run EOS', 'SOS run EOS', 'SOS run EOS', 'SOS who EOS', 'SOS wow EOS', 'SOS jump EOS', 'SOS jump EOS', 'SOS jump EOS', 'SOS jump EOS']\n",
            "[[864, 782, 48], [864, 840, 48], [864, 840, 48], [864, 840, 48], [864, 119, 48], [864, 646, 48], [864, 855, 48], [864, 855, 48], [864, 855, 48], [864, 855, 48]]\n",
            "[[782, 48], [840, 48], [840, 48], [840, 48], [119, 48], [646, 48], [855, 48], [855, 48], [855, 48], [855, 48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DiZw3UuFCVkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "4ee5083b-6807-4d94-8467-6611d7315166"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_encoder = pad_sequences(X_encoder)\n",
        "X_decoder = pad_sequences(X_decoder)\n",
        "Y = pad_sequences(Y, maxlen=X_decoder.shape[1])\n",
        "\n",
        "print(X_encoder.shape)\n",
        "print(X_decoder.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10000, 9)\n",
            "(10000, 6)\n",
            "(10000, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wTqa-iCFF88S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f538ce97-4cab-4ea3-8522-85401d234b19"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "Y_oh = np.zeros((Y.shape[0], Y.shape[1], len(eng_dict)))\n",
        "\n",
        "for i in range(len(Y)):\n",
        "  for j in range(len(Y[i])):\n",
        "    Y_oh[i][j][Y[i][j]]=1\n",
        "    \n",
        "Y_oh.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 6, 1412)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "0RuGBRpe5wtt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "58451d5b-779f-442c-fed0-4cda1865dd8b"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding\n",
        "\n",
        "latent_dim = 256\n",
        "num_encoder_tokens = len(ita_dict)\n",
        "num_decoder_tokens = len(eng_dict)\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "x = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
        "x, state_h, state_c = LSTM(latent_dim,\n",
        "                           return_state=True)(x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "x = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n",
        "x = LSTM(latent_dim, return_sequences=True)(x, initial_state=encoder_states)\n",
        "decoder_outputs = Dense(num_decoder_tokens, activation='softmax')(x)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile & run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "# Note that `decoder_target_data` needs to be one-hot encoded,\n",
        "# rather than sequences of integers like `decoder_input_data`!"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tFciuNTCEdU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "86104d09-6bfc-4682-9f1c-de76f17b2599"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 256)    914176      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 256)    361472      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 525312      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, None, 256)    525312      embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 1412)   362884      lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 2,689,156\n",
            "Trainable params: 2,689,156\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "umDCTkZlEbz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3603
        },
        "outputId": "93a8e076-2190-4411-dbaf-af7ae2f63948"
      },
      "cell_type": "code",
      "source": [
        "model.fit([X_encoder, X_decoder], Y_oh,\n",
        "          batch_size=512,\n",
        "          epochs=100,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 5s 574us/step - loss: 3.9157 - val_loss: 3.1142\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 1s 123us/step - loss: 2.6158 - val_loss: 2.9633\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 2.4201 - val_loss: 2.8196\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 2.2646 - val_loss: 2.7354\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 1s 125us/step - loss: 2.1380 - val_loss: 2.6581\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 2.0032 - val_loss: 2.5219\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 1.8705 - val_loss: 2.4549\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 1.7344 - val_loss: 2.3558\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 1.6053 - val_loss: 2.2234\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 1s 116us/step - loss: 1.4630 - val_loss: 2.1494\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 1.3292 - val_loss: 2.0251\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 1s 116us/step - loss: 1.1912 - val_loss: 1.9412\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 1.0635 - val_loss: 1.8458\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.9414 - val_loss: 1.7791\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.8253 - val_loss: 1.6757\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.7219 - val_loss: 1.6039\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.6242 - val_loss: 1.5537\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.5369 - val_loss: 1.4988\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 0.4578 - val_loss: 1.4511\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.3889 - val_loss: 1.4094\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 0.3276 - val_loss: 1.3665\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 0.2739 - val_loss: 1.3257\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.2276 - val_loss: 1.2941\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.1890 - val_loss: 1.2709\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.1567 - val_loss: 1.2349\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.1297 - val_loss: 1.2151\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.1063 - val_loss: 1.1964\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.0877 - val_loss: 1.1759\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 1s 121us/step - loss: 0.0725 - val_loss: 1.1565\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.0599 - val_loss: 1.1393\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.0484 - val_loss: 1.1222\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.0404 - val_loss: 1.1061\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.0333 - val_loss: 1.0940\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.0274 - val_loss: 1.0756\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.0227 - val_loss: 1.0672\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.0189 - val_loss: 1.0467\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.0155 - val_loss: 1.0425\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.0131 - val_loss: 1.0257\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.0108 - val_loss: 1.0232\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.0091 - val_loss: 1.0047\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 0.0076 - val_loss: 1.0031\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.0064 - val_loss: 0.9903\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 0.0053 - val_loss: 0.9753\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 0.0045 - val_loss: 0.9672\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.0037 - val_loss: 0.9588\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.0031 - val_loss: 0.9472\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.0026 - val_loss: 0.9422\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.0022 - val_loss: 0.9318\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 0.0018 - val_loss: 0.9220\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 0.0016 - val_loss: 0.9028\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.0013 - val_loss: 0.9092\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.0011 - val_loss: 0.9095\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 8.7724e-04 - val_loss: 0.8993\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 7.3717e-04 - val_loss: 0.8901\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 1s 125us/step - loss: 6.1254e-04 - val_loss: 0.8752\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 1s 125us/step - loss: 4.9547e-04 - val_loss: 0.8757\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 1s 124us/step - loss: 4.2339e-04 - val_loss: 0.8673\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 1s 124us/step - loss: 3.4806e-04 - val_loss: 0.8541\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 1s 123us/step - loss: 2.8637e-04 - val_loss: 0.8523\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 2.4948e-04 - val_loss: 0.8508\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 2.0156e-04 - val_loss: 0.8465\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 1.6951e-04 - val_loss: 0.8399\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 1.4296e-04 - val_loss: 0.8350\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 1.2278e-04 - val_loss: 0.8288\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 1.0128e-04 - val_loss: 0.8285\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 8.7155e-05 - val_loss: 0.8183\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 1s 121us/step - loss: 7.4912e-05 - val_loss: 0.8171\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 6.4705e-05 - val_loss: 0.8105\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 5.5920e-05 - val_loss: 0.8094\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 1s 125us/step - loss: 4.8979e-05 - val_loss: 0.8029\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 1s 124us/step - loss: 4.2416e-05 - val_loss: 0.8044\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 1s 124us/step - loss: 3.7576e-05 - val_loss: 0.7921\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 1s 123us/step - loss: 3.3490e-05 - val_loss: 0.8007\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 2.9907e-05 - val_loss: 0.7888\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 2.6512e-05 - val_loss: 0.7885\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 1s 124us/step - loss: 2.4107e-05 - val_loss: 0.7812\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 1s 121us/step - loss: 2.1824e-05 - val_loss: 0.7865\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 2.0002e-05 - val_loss: 0.7816\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 1.8209e-05 - val_loss: 0.7818\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 1.6721e-05 - val_loss: 0.7828\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 1s 119us/step - loss: 1.5537e-05 - val_loss: 0.7795\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 1.4370e-05 - val_loss: 0.7818\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 1s 124us/step - loss: 1.3383e-05 - val_loss: 0.7785\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 1s 123us/step - loss: 1.2498e-05 - val_loss: 0.7794\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 1s 124us/step - loss: 1.1770e-05 - val_loss: 0.7780\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 1s 123us/step - loss: 1.1081e-05 - val_loss: 0.7795\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 1.0455e-05 - val_loss: 0.7793\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 1s 123us/step - loss: 9.8697e-06 - val_loss: 0.7779\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 1s 123us/step - loss: 9.4004e-06 - val_loss: 0.7801\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 1s 123us/step - loss: 8.9353e-06 - val_loss: 0.7786\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 8.5359e-06 - val_loss: 0.7787\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 1s 124us/step - loss: 8.1445e-06 - val_loss: 0.7765\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 1s 124us/step - loss: 7.8031e-06 - val_loss: 0.7783\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 1s 121us/step - loss: 7.4769e-06 - val_loss: 0.7789\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 1s 121us/step - loss: 7.1963e-06 - val_loss: 0.7789\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 1s 121us/step - loss: 6.9318e-06 - val_loss: 0.7785\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 1s 121us/step - loss: 6.6770e-06 - val_loss: 0.7782\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 6.4487e-06 - val_loss: 0.7794\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 1s 122us/step - loss: 6.2216e-06 - val_loss: 0.7798\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 1s 120us/step - loss: 6.0256e-06 - val_loss: 0.7816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f91f5ad5ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "1SW79zgCAa1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "7721bee6-16a1-4ee0-92c8-b62edce2e646"
      },
      "cell_type": "code",
      "source": [
        "ita_sent = \"ciao\"\n",
        "\n",
        "ita_sent = [ita_dict_rev[ita_sent]]\n",
        "\n",
        "ita_sent = pad_sequences([ita_sent], maxlen=9)\n",
        "\n",
        "ita_sent = np.array([ita_sent])\n",
        "\n",
        "print(ita_sent.shape)\n",
        "\n",
        "y = model.predict(ita_sent)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-44391dec1f85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mita_sent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mita_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[   0,    0,    0,    0,    0,    0,    0,    0, 1455]]],\n      dtype=int32)]..."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HmFyxUA9wPO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb8e89f1-6cbd-41e5-a632-0f2ed883f522"
      },
      "cell_type": "code",
      "source": [
        "X_encoder.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "dwmdOqmVw6Rc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}