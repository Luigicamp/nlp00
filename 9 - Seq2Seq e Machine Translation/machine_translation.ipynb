{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/nlp00/blob/master/9%20-%20Seq2Seq%20e%20Machine%20Translation/machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PKRyLzAhw-IC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "0adfe100-8bd4-4943-d9d2-c9d486d6f16f"
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.manythings.org/anki/ita-eng.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-19 13:25:15--  http://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6dc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3981147 (3.8M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "\rita-eng.zip           0%[                    ]       0  --.-KB/s               \rita-eng.zip          22%[===>                ] 868.86K  4.18MB/s               \rita-eng.zip         100%[===================>]   3.80M  13.7MB/s    in 0.3s    \n",
            "\n",
            "2019-04-19 13:25:16 (13.7 MB/s) - ‘ita-eng.zip’ saved [3981147/3981147]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A4Se2U15xbB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4146b03e-9de7-4536-b8f9-29533b674125"
      },
      "cell_type": "code",
      "source": [
        "!unzip ita-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mEeEpIPvxeKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "b9972d9b-1f88-45a4-f1c5-2497773926b9"
      },
      "cell_type": "code",
      "source": [
        "with open(\"ita.txt\") as eng_ita_sents:\n",
        "  eng_ita_sents = eng_ita_sents.read().split(\"\\n\")\n",
        "\n",
        "print(\"%d esempi\\n\" % len(eng_ita_sents))\n",
        "  \n",
        "for i in range(5):\n",
        "  print(eng_ita_sents[i])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "321434 esempi\n",
            "\n",
            "Hi.\tCiao!\n",
            "Run!\tCorri!\n",
            "Run!\tCorra!\n",
            "Run!\tCorrete!\n",
            "Who?\tChi?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XcG3xVrXx5OO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a7bbc05-6e8e-48aa-b3ba-51aa98bee5db"
      },
      "cell_type": "code",
      "source": [
        "eng_sents = []\n",
        "ita_sents = []\n",
        "\n",
        "for eng_ita_sent in eng_ita_sents:\n",
        "  eng_ita_sent = eng_ita_sent.split(\"\\t\")\n",
        "  if(len(eng_ita_sent)==2):\n",
        "    eng_sents.append(eng_ita_sent[0])\n",
        "    ita_sents.append(eng_ita_sent[1])\n",
        "\n",
        "print(eng_sents[:5])\n",
        "print(ita_sents[:5])      "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi.', 'Run!', 'Run!', 'Run!', 'Who?']\n",
            "['Ciao!', 'Corri!', 'Corra!', 'Correte!', 'Chi?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LuQjnKmTzNWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f01c3832-4ae6-4783-ee07-449e44cb1c01"
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'[^\\w\\s]','',text)\n",
        "  text = \"SOS \"+text+\" EOS\"\n",
        "  return text\n",
        "\n",
        "\n",
        "ita_sents = [preprocess(ita_sent) for ita_sent in ita_sents]\n",
        "eng_sents = [preprocess(eng_sent) for eng_sent in eng_sents]\n",
        "\n",
        "print(eng_sents[:5])\n",
        "print(ita_sents[:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SOS hi EOS', 'SOS run EOS', 'SOS run EOS', 'SOS run EOS', 'SOS who EOS']\n",
            "['SOS ciao EOS', 'SOS corri EOS', 'SOS corra EOS', 'SOS correte EOS', 'SOS chi EOS']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P23dJENI2Zx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70957ad6-f898-4f3f-f2a8-8db5861ee8e6"
      },
      "cell_type": "code",
      "source": [
        "def get_dictionary(sents):\n",
        "  \n",
        "  dictionary = set({})\n",
        "  \n",
        "  for sent in sents:\n",
        "    dictionary|=set(sent.split())\n",
        "    \n",
        "  return list(dictionary)\n",
        "\n",
        "\n",
        "eng_dict = get_dictionary(eng_sents)\n",
        "ita_dict = get_dictionary(ita_sents)\n",
        "\n",
        "print(\"%d parole nel dizionario inglese\" % len(eng_dict))\n",
        "print(\"%d parole nel dizionario italiano\" % len(ita_dict))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13437 parole nel dizionario inglese\n",
            "27162 parole nel dizionario italiano\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8AdVrq4A5DQC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eng_dict_rev = {k: v for k, v in zip(eng_dict, range(len(eng_dict)))}\n",
        "ita_dict_rev = {k: v for k, v in zip(ita_dict, range(len(ita_dict)))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MR58SPEq3uNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fa8ce74d-2cfa-4561-8d0f-8cf5db07bd29"
      },
      "cell_type": "code",
      "source": [
        "def encode(sents, dict_rev):\n",
        "  \n",
        "  sents_enc = []\n",
        "  \n",
        "  for sent in sents:\n",
        "    sents_enc.append([dict_rev[word] for word in sent.split()])\n",
        "    \n",
        "  return sents_enc\n",
        "\n",
        "X_encoder = encode(ita_sents, ita_dict_rev)\n",
        "X_decoder = encode(eng_sents, eng_dict_rev)\n",
        "\n",
        "Y = []\n",
        "\n",
        "for x in X_decoder:\n",
        "  Y.append(x[1:])\n",
        "\n",
        "print(eng_sents[:10])\n",
        "print(X_decoder[:10])\n",
        "print(Y[:10])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SOS hi EOS', 'SOS run EOS', 'SOS run EOS', 'SOS run EOS', 'SOS who EOS', 'SOS wow EOS', 'SOS jump EOS', 'SOS jump EOS', 'SOS jump EOS', 'SOS jump EOS']\n",
            "[[465, 4452, 463], [465, 5408, 463], [465, 5408, 463], [465, 5408, 463], [465, 1118, 463], [465, 9211, 463], [465, 4860, 463], [465, 4860, 463], [465, 4860, 463], [465, 4860, 463]]\n",
            "[[4452, 463], [5408, 463], [5408, 463], [5408, 463], [1118, 463], [9211, 463], [4860, 463], [4860, 463], [4860, 463], [4860, 463]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wTqa-iCFF88S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "Y_oh = np.zeros((len(Y), len(eng_dict)))\n",
        "\n",
        "for y in Y[0]:\n",
        "  y_oh[y] = 1\n",
        "  Y_oh.append(y_oh)\n",
        "  \n",
        "Y_oh.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DiZw3UuFCVkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49ef4388-0af2-464b-9609-d3799ee65267"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_encoder = pad_sequences(X_encoder)\n",
        "X_decoder = pad_sequences(X_decoder)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yGBqrH-2Etmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c203fa83-074c-4eb9-a6e3-599c60bbcb97"
      },
      "cell_type": "code",
      "source": [
        "print(X_encoder.shape)\n",
        "print(X_decoder.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(321433, 51)\n",
            "(321433, 49)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0RuGBRpe5wtt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding\n",
        "\n",
        "latent_dim = 256\n",
        "num_encoder_tokens = len(ita_dict)\n",
        "num_decoder_tokens = len(eng_dict)\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "x = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
        "x, state_h, state_c = LSTM(latent_dim,\n",
        "                           return_state=True)(x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "x = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n",
        "x = LSTM(latent_dim, return_sequences=True)(x, initial_state=encoder_states)\n",
        "decoder_outputs = Dense(num_decoder_tokens, activation='softmax')(x)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile & run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "# Note that `decoder_target_data` needs to be one-hot encoded,\n",
        "# rather than sequences of integers like `decoder_input_data`!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tFciuNTCEdU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "7e4b5368-d3ef-4197-8c03-4ce91efc18ad"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 256)    6953472     input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, None, 256)    3439872     input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, 256), (None, 525312      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, None, 256)    525312      embedding_4[0][0]                \n",
            "                                                                 lstm_3[0][1]                     \n",
            "                                                                 lstm_3[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 13437)  3453309     lstm_4[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 14,897,277\n",
            "Trainable params: 14,897,277\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "umDCTkZlEbz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "fd63fbc9-621e-48a4-a8f2-7f4f30712603"
      },
      "cell_type": "code",
      "source": [
        "model.fit([X_encoder, X_decoder], Y,\n",
        "          batch_size=512,\n",
        "          epochs=100,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-4b1c51b103e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_split=0.2)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have 3 dimensions, but got array with shape (321433, 41481)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1SW79zgCAa1c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}